"""
Building a Sentiment Corpus of Tweets in Brazilian Portuguese
http://www.lrec-conf.org/proceedings/lrec2018/summaries/389.html

TweetSentBR is a sentiment corpus for Brazilian Portuguese manually annotated 
with 15.000 sentences on TV show domain. The sentences were labeled in three 
classes (positive, neutral and negative) by seven annotators, following 
literature guidelines for ensuring reliability on the annotation. 

Homepage: "https://bitbucket.org/HBrum/tweetsentbr/src/master/"
"""
import os
import re
from lm_eval import utils
import numpy as np
import pandas as pd
import json
import glob
import datasets
from sklearn.metrics import f1_score
from scipy.stats import pearsonr
from lm_eval.base import rf, Task
from ..metrics import mean

_CITATION = """
@InProceedings{BRUM18.389,
  author = {Henrico Brum and Maria das Gra\c{c}as Volpe Nunes},
  title = "{Building a Sentiment Corpus of Tweets in Brazilian Portuguese}",
  booktitle = {Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)},
  year = {2018},
  month = {May 7-12, 2018},
  address = {Miyazaki, Japan},
  editor = {Nicoletta Calzolari (Conference chair) and Khalid Choukri and Christopher Cieri and Thierry Declerck and Sara Goggi and Koiti Hasida and Hitoshi Isahara and Bente Maegaard and Joseph Mariani and HÚlŔne Mazo and Asuncion Moreno and Jan Odijk and Stelios Piperidis and Takenobu Tokunaga},
  publisher = {European Language Resources Association (ELRA)},
  isbn = {979-10-95546-00-9},
  language = {english}
}
"""

class TweetSentBR(Task):
    VERSION = 0
    DATASET_PATH = "data/tweetsentbr"
    DATASET_NAME = None

    def download(self, data_dir=None, cache_dir=None, download_mode=None):
        """ Dowloading the dataset requires the use of an API key. To use the 
        dataset for academic purpose, please contact the corresponding author 
        Henrico Brum. The dataset is originally in TSV format, and comes with 
        a parsing code that converts to a JSON file.
        """
        self.dataset = {}
        # using version of Henrico
        data = pd.read_json(os.path.join(self.DATASET_PATH, 'tweetsentbr.json'), orient='index')

        # remove N/A
        data.dropna(subset=['text'], inplace=True)
        
        # remove cases undefined class (Henrico version)
        data = data[data.sentiment != '-']

        # set labels
        data.sentiment = data.sentiment.astype(int) + 1

        # remove double spaces
        data.text = data.text.apply(lambda x: re.sub(r'(\s)\1*', r' ', x))

        self.dataset['train'] = data.loc[data['group'] == 'train'].drop(columns=['group'])
        self.dataset['test'] = data.loc[data['group'] == 'test'].drop(columns=['group'])

        self.dataset['train'] = self.dataset['train'].to_dict(orient='records')
        self.dataset['test'] = self.dataset['test'].to_dict(orient='records')

    def has_training_docs(self):
        return True

    def has_validation_docs(self):
        return True

    def has_test_docs(self):
        return True

    def training_docs(self):
        return self.dataset["train"]

    def validation_docs(self):
       return self.dataset["test"]

    def test_docs(self):
        print(len(self.dataset["test"]))
        return self.dataset["test"]

    def doc_to_text(self, doc):
        return f"Mensagem: \"{doc['text']}\".\n\nResposta:"

    def doc_to_target(self, doc):
        return " " + ["negativa", "neutra", "positiva"][doc['sentiment']]

    def construct_requests(self, doc, ctx):
        """ Uses RequestFactory to construct Requests and returns an iterable of 
        Requests which will be sent to the LM.

        :param doc:
            The document as returned from training_docs, validation_docs, or test_docs.
        :param ctx: str
            The context string, generated by fewshot_context. This includes the natural 
            language description, as well as the few shot examples, and the question
            part of the document for `doc`. 
        """
        # print('--------\nINPUT:\n--------\n', ctx, '\n\n')
        print('--------\nINPUT:\n--------\n', doc['text'], '\n\n')
        ll_negativa, _ = rf.loglikelihood(ctx, " negativa") 
        ll_neutra, _ = rf.loglikelihood(ctx, " neutra") 
        ll_positiva, _ = rf.loglikelihood(ctx, " positiva") 
        return ll_negativa, ll_neutra, ll_positiva
    
    def process_results(self, doc, results):
        """Take a single document and the LM results and evaluates, returning a 
        dict where keys are the names of submetrics and values are the values of 
        the metric for that one document

        :param doc:
            The document as returned from training_docs, validation_docs, or test_docs.
        :param results:
            The results of the requests created in construct_requests.
        """
        gold = doc['sentiment']
        pred = np.argmax(results)
        print(f'gold: {gold}, pred: {pred}')
        return {
            "acc": (pred == gold) * 100.0,
            "f1-macro": (pred, gold),
            "f1-weighted": (pred, gold),
        }

    @classmethod
    def macro_f1(cls, items):
        preds, golds = zip(*items)
        preds = np.array(preds)
        golds = np.array(golds)
        label_set = set(golds)
        macro_f1 = f1_score(golds, preds, average='macro', 
                        labels=list(label_set))
        return macro_f1 * 100.0

    @classmethod
    def weighted_f1(cls, items):
        preds, golds = zip(*items)
        preds = np.array(preds)
        golds = np.array(golds)
        label_set = set(golds)
        weighted_f1 = f1_score(golds, preds, average='weighted', 
                        labels=list(label_set))
        return weighted_f1 * 100.0

    def aggregation(self):
        """
        :returns: {str: [float] -> float}
            A dictionary where keys are the names of submetrics and values are 
            functions that aggregate a list of metrics
        """
        return {
            "acc": mean,
            "f1-macro": self.macro_f1,
            "f1-weighted": self.weighted_f1,
        }

    def higher_is_better(self):
        """
        :returns: {str: bool}
            A dictionary where keys are the names of submetrics and values are 
            whether a higher value of the submetric is better
        """
        return {
            "acc": True,
            "f1-macro": True,
            "f1-weighted": True,
        }

    def fewshot_examples(self, k, rnd):
        if self._training_docs is None:
            self._training_docs = list(self.training_docs())

        # Indexes of first examples of classes negativa, neutra and positiva interleaved
        indexes = [0, 1, 2, 6, 34, 3, 10, 54, 4, 11, 116, 5, 12, 236, 7, 15, 265, 
                8, 19, 289, 9, 20, 330, 13, 24, 356, 14, 26, 417, 16, 33, 418, 17, 
                39, 420, 18, 40, 421, 21, 41, 422, 22, 46, 427, 23, 48, 434, 25, 
                49, 437, 27, 51, 438, 28, 57, 448, 29, 60, 449, 30]

        # return rnd.sample(self._training_docs, k)
        return [ self._training_docs[i] for i in indexes[:k] ]

    @utils.positional_deprecated
    def fewshot_context(
        self, doc, num_fewshot, provide_description=None, rnd=None, description=None
    ):
        """Returns a fewshot context string that is made up of a prepended description
        (if provided), the `num_fewshot` number of examples, and an appended prompt example.
        :param doc: str
            The document as returned from training_docs, validation_docs, or test_docs.
        :param num_fewshot: int
            The number of fewshot examples to provide in the returned context string.
        :param provide_description: bool
            Not implemented, and this option is deprecated and will be removed in a future version in favor of a different description providing method
        :param rnd: random.Random
            The pseudo-random number generator used to randomly sample examples.
            WARNING: This is currently a required arg although it's optionalized with a default `None`.
        :param description: str
            The task's description that will be prepended to the fewshot examples.
        :returns: str
            The fewshot context.
        """
        assert (
            rnd is not None
        ), "A `random.Random` generator argument must be provided to `rnd`"
        assert not provide_description, (
            "The `provide_description` arg will be removed in future versions. To prepend "
            "a custom description to the context, supply the corresponding string via the "
            "`description` arg."
        )
        if provide_description is not None:
            # nudge people to not specify it at all
            print(
                "WARNING: provide_description is deprecated and will be removed in a future version in favor of description_dict"
            )

        description = description + "\n\n\n" if description else ""

        if num_fewshot == 0:
            labeled_examples = ""
        else:
            # for sets with no training docs, draw from other set *but ensure no overlap with current doc*
            if self.has_training_docs():
                fewshotex = self.fewshot_examples(k=num_fewshot, rnd=rnd)
            else:
                if self._fewshot_docs is None:
                    self._fewshot_docs = list(
                        self.validation_docs()
                        if self.has_validation_docs()
                        else self.test_docs()
                    )

                fewshotex = rnd.sample(self._fewshot_docs, num_fewshot + 1)

                # get rid of the doc that's the one we're evaluating, if it's in the fewshot
                fewshotex = [x for x in fewshotex if x != doc][:num_fewshot]

            labeled_examples = ''
            for i, doc_ex in enumerate(fewshotex):
                labeled_examples += f'Exemplo {i+1}:\n\n'
                labeled_examples += self.doc_to_text(doc_ex) + self.doc_to_target(doc_ex)
                labeled_examples += '\n\n\n'
            labeled_examples += f'Exemplo {len(fewshotex) + 1}:\n\n'

        example = self.doc_to_text(doc)
        return description + labeled_examples + example
